{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72e8165-dcaa-4ee7-868b-31c7a5a4a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded: (397924, 9)\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice CustomerID         Country  TotalPrice  \n",
      "0 2010-12-01 08:26:00       2.55    17850.0  United Kingdom       15.30  \n",
      "1 2010-12-01 08:26:00       3.39    17850.0  United Kingdom       20.34  \n",
      "2 2010-12-01 08:26:00       2.75    17850.0  United Kingdom       22.00  \n",
      "3 2010-12-01 08:26:00       3.39    17850.0  United Kingdom       20.34  \n",
      "4 2010-12-01 08:26:00       3.39    17850.0  United Kingdom       20.34  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_clean_data(path=\"OnlineRetail.csv\"):\n",
    "    \"\"\"\n",
    "    Load and clean Online Retail dataset.\n",
    "    Removes missing CustomerIDs, negative quantities, and invalid invoices.\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(path, encoding='unicode_escape')\n",
    "\n",
    "    # Remove missing Customer IDs\n",
    "    df = df.dropna(subset=['CustomerID'])\n",
    "\n",
    "    # Remove negative quantities (returns)\n",
    "    df = df[df['Quantity'] > 0]\n",
    "\n",
    "    # Convert columns\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    df['CustomerID'] = df['CustomerID'].astype(str)\n",
    "\n",
    "    # Compute total price\n",
    "    df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_and_clean_data()\n",
    "    print(\"‚úÖ Data loaded:\", data.shape)\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4735d2fe-cf7a-4aa4-85c5-976e6db73e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Recency  Frequency  Monetary  Churn\n",
      "0     12346.0      326          1  77183.60      1\n",
      "1     12347.0        2          7   4310.00      0\n",
      "2     12348.0       75          4   1797.24      0\n",
      "3     12349.0       19          1   1757.55      0\n",
      "4     12350.0      310          1    334.40      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def create_customer_features(df):\n",
    "    \"\"\"\n",
    "    Create customer-level features (RFM + behavior features).\n",
    "    \"\"\"\n",
    "    ref_date = df['InvoiceDate'].max() + timedelta(days=1)\n",
    "\n",
    "    rfm = df.groupby('CustomerID').agg({\n",
    "        'InvoiceDate': lambda x: (ref_date - x.max()).days,  # Recency\n",
    "        'InvoiceNo': 'nunique',  # Frequency\n",
    "        'TotalPrice': 'sum'      # Monetary\n",
    "    }).reset_index()\n",
    "\n",
    "    rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "    # Add churn label: if no purchase in last 90 days ‚Üí churn\n",
    "    rfm['Churn'] = (rfm['Recency'] > 90).astype(int)\n",
    "\n",
    "    return rfm\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ‚úÖ Option 1: If the function exists in etl.py\n",
    "    from etl import load_and_clean_data   # or from etl import load_data\n",
    "\n",
    "    df = load_and_clean_data()            # or df = load_data()\n",
    "    features = create_customer_features(df)\n",
    "    print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a9cb64-68eb-4e71-afa1-6735db34866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy: 0.9942396313364056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       569\n",
      "           1       1.00      0.98      0.99       299\n",
      "\n",
      "    accuracy                           0.99       868\n",
      "   macro avg       1.00      0.99      0.99       868\n",
      "weighted avg       0.99      0.99      0.99       868\n",
      "\n",
      "üíæ Model and scaler saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from etl import load_and_clean_data\n",
    "from features import create_customer_features\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    # Load and prepare data\n",
    "    df = load_and_clean_data()\n",
    "    features = create_customer_features(df)\n",
    "\n",
    "    X = features[['Recency', 'Frequency', 'Monetary']]\n",
    "    y = features['Churn']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(\"‚úÖ Accuracy:\", acc)\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    # Ensure the models folder exists\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    # Save model & scaler\n",
    "    joblib.dump(model, \"models/churn_model.pkl\")\n",
    "    joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "    print(\"üíæ Model and scaler saved!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b2446b-1bd5-4508-95a3-48760fddec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 18:38:24.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:24.452 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:24.453 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:24.454 No runtime found, using MemoryCacheStorageManager\n",
      "2025-11-15 18:38:24.455 No runtime found, using MemoryCacheStorageManager\n",
      "2025-11-15 18:38:24.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:24.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.005 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.006 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.007 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.010 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.011 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.155 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-15 18:38:25.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import joblib\n",
    "from etl import load_and_clean_data\n",
    "from features import create_customer_features\n",
    "\n",
    "st.set_page_config(page_title=\"Customer Churn & Sales Dashboard\", layout=\"wide\")\n",
    "\n",
    "st.title(\"üìä Customer Churn Prediction and Sales Dashboard\")\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    return load_and_clean_data()\n",
    "\n",
    "@st.cache_data\n",
    "def compute_features(df):\n",
    "    return create_customer_features(df)\n",
    "\n",
    "# Load data\n",
    "df = load_data()\n",
    "features = compute_features(df)\n",
    "\n",
    "# --- Sales Trends ---\n",
    "st.header(\"üí∞ Sales Trends Over Time\")\n",
    "\n",
    "df['Month'] = df['InvoiceDate'].dt.to_period('M').astype(str)\n",
    "monthly_sales = df.groupby('Month')['TotalPrice'].sum().reset_index()\n",
    "\n",
    "fig_sales = px.line(monthly_sales, x='Month', y='TotalPrice', title=\"Monthly Sales Trend\")\n",
    "st.plotly_chart(fig_sales, use_container_width=True)\n",
    "\n",
    "# --- Top Products ---\n",
    "st.header(\"üèÜ Top Products\")\n",
    "top_products = df.groupby('Description')['TotalPrice'].sum().nlargest(10).reset_index()\n",
    "fig_products = px.bar(top_products, x='Description', y='TotalPrice', title=\"Top 10 Products\")\n",
    "st.plotly_chart(fig_products, use_container_width=True)\n",
    "\n",
    "# --- Churn Prediction ---\n",
    "st.header(\"üîÆ Customer Churn Prediction\")\n",
    "\n",
    "try:\n",
    "    model = joblib.load(\"models/churn_model.pkl\")\n",
    "    scaler = joblib.load(\"models/scaler.pkl\")\n",
    "except:\n",
    "    st.error(\"Model not found. Please run train_model.py first.\")\n",
    "    st.stop()\n",
    "\n",
    "customer_id = st.selectbox(\"Select Customer ID\", features['CustomerID'])\n",
    "row = features[features['CustomerID'] == customer_id][['Recency', 'Frequency', 'Monetary']]\n",
    "\n",
    "scaled = scaler.transform(row)\n",
    "prob = model.predict_proba(scaled)[0][1]\n",
    "\n",
    "st.metric(\"Churn Probability\", f\"{prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63dd1d-4439-4793-a2c0-fb9db1a7a822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
